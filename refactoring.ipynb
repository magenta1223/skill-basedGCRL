{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = hydra.main(config_path=\"./LVD/configs\", config_name=\"spirl_kitchen\", version_base= \"1.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LVD.modules.base.LinearBlock"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import LVD\n",
    "\n",
    "LVD.modules.LinearBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LVD.modules.base.LinearBlock"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydra.utils.get_class(\"LVD.modules.LinearBlock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20197/3504557975.py:9: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize(config_path= \"./LVD/configs\"):\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "\n",
    "with open(\"/home/magenta1223/skill-based/SiMPL/GCPrior/LVD/configs/spirl_kitchen.yaml\", mode = \"rb\") as f:\n",
    "    cfg = yaml.load(f, yaml.Loader)\n",
    "\n",
    "\n",
    "\n",
    "with hydra.initialize(config_path= \"./LVD/configs\"):\n",
    "    cfg = hydra.compose(\"spirl_kitchen.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'save_path': './weights', 'log_path': './log.txt', 'save_ckpt': 20, 'early_stop_rounds': 100, 'n_rollout_steps': 10, 'workers': 14, 'dataset_size': -1, 'val_data_size': 5000, 'batch_size': 1024, 'lr': 0.001, 'init_grad_clip': 5.0, 'init_grad_clip_step': 0, 'schedulerClass': 'LVD.utils.Scheduler_Helper', 'scheduler_params': {'mode': 'min', 'factor': 0.2, 'patience': 6, 'verbose': True, 'threshold': 1e-05, 'threshold_mode': 'abs', 'min_lr': 1e-12}, 'model': {'subseq_len': 11, 'prior': {'n_blocks': 5, 'hidden_dim': 128, 'out_dim': 20, 'module_type': 'linear', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.LayerNorm', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'in_feature': 30}, 'skill_encoder': {'n_blocks': 1, 'hidden_dim': 128, 'out_dim': 20, 'module_type': 'rnn', 'rnn_cls': 'torch.nn.LSTM', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.LayerNorm', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'batch_first': True, 'in_feature': 39}, 'skill_decoder': {'n_blocks': 5, 'hidden_dim': 128, 'out_dim': 9, 'module_type': 'linear', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.BatchNorm1d', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'in_feature': 40}, 'high_policy': {'n_blocks': 5, 'hidden_dim': 128, 'out_dim': 20, 'module_type': 'linear', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.BatchNorm1d', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'in_feature': 60}}, 'env': {'env_name': 'kitchen', 'env_name_offline': 'kitchen-mixed-v0', 'robotics': True, 'state_dim': 30, 'n_obj': 9, 'n_env': 21, 'n_goal': 30, 'action_dim': 9, 'normalize': False, 'subseq_len': 11, 'max_seq_len': 280, 'data_dir': '.', 'epoch_cycles_train': 50, 'batch_size': 1024, 'mixin_start': 30, 'mixin_ratio': 0.05, 'plan_H': 100, 'epochs': 70, 'warmup_steps': 30, 'latent_dim': 10, 'latent_state_dim': 32, 'reg_beta': 0.0005, 'prior_state_dim': 30, 'wae_coef': 1, 'val_data_size': 5000, 'time_limit': 280, 'target_kl_start': 50, 'target_kl_end': 15, 'init_alpha': 0.0005, 'only_increase': True, 'auto_alpha': False, 'reuse_rate': 512, 'q_warmup': 5000, 'q_weight': 1, 'precollect': 20, 'early_stop_threshold': 0.8, 'max_reward': 4, 'use_hidden': True, 'consistency_lr': 1e-08, 'policy_lr': 3e-06}, 'dataset_cls': 'LVD.data.kitchen.kitchen_dataloader.Kitchen_Dataset', 'structure': 'sc'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_cfg(cfg):\n",
    "    \"\"\"\n",
    "    1. value가 dict면 -> 다 까보기\n",
    "    2. value가 dict가 아니면\n",
    "        - class로 만들 수 있나? -> cls로\n",
    "        - 아니면 -> value로 \n",
    "    3. cls로 다 바꾼 후 원래 구조의 dictioanry로 변경! \n",
    "    \"\"\"\n",
    "    \n",
    "    new_cfg = dict()\n",
    "    \n",
    "    for k, v in cfg.items():\n",
    "        print(type(v))\n",
    "        if isinstance(v, dict):\n",
    "            v = get_class_cfg(v)\n",
    "        elif isinstance(v, str) and \".\" in v and \"/\" not in v:\n",
    "            print(v)\n",
    "            v = hydra.utils.get_class(v)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "        new_cfg[k] = v\n",
    "\n",
    "    return new_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subseq_len': 11, 'prior': {'n_blocks': 5, 'hidden_dim': 128, 'out_dim': 20, 'module_type': 'linear', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.LayerNorm', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'in_feature': 30}, 'skill_encoder': {'n_blocks': 1, 'hidden_dim': 128, 'out_dim': 20, 'module_type': 'rnn', 'rnn_cls': 'torch.nn.LSTM', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.LayerNorm', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'batch_first': True, 'in_feature': 39}, 'skill_decoder': {'n_blocks': 5, 'hidden_dim': 128, 'out_dim': 9, 'module_type': 'linear', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.BatchNorm1d', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'in_feature': 40}, 'high_policy': {'n_blocks': 5, 'hidden_dim': 128, 'out_dim': 20, 'module_type': 'linear', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.BatchNorm1d', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'in_feature': 60}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'int'>\n",
      "<class 'str'>\n",
      "LVD.utils.Scheduler_Helper\n",
      "<class 'omegaconf.dictconfig.DictConfig'>\n",
      "<class 'omegaconf.dictconfig.DictConfig'>\n",
      "<class 'omegaconf.dictconfig.DictConfig'>\n",
      "<class 'str'>\n",
      "LVD.data.kitchen.kitchen_dataloader.Kitchen_Dataset\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'save_path': './weights',\n",
       " 'log_path': './log.txt',\n",
       " 'save_ckpt': 20,\n",
       " 'early_stop_rounds': 100,\n",
       " 'n_rollout_steps': 10,\n",
       " 'workers': 14,\n",
       " 'dataset_size': -1,\n",
       " 'val_data_size': 5000,\n",
       " 'batch_size': 1024,\n",
       " 'lr': 0.001,\n",
       " 'init_grad_clip': 5.0,\n",
       " 'init_grad_clip_step': 0,\n",
       " 'schedulerClass': LVD.utils.Scheduler_Helper,\n",
       " 'scheduler_params': {'mode': 'min', 'factor': 0.2, 'patience': 6, 'verbose': True, 'threshold': 1e-05, 'threshold_mode': 'abs', 'min_lr': 1e-12},\n",
       " 'model': {'subseq_len': 11, 'prior': {'n_blocks': 5, 'hidden_dim': 128, 'out_dim': 20, 'module_type': 'linear', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.LayerNorm', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'in_feature': 30}, 'skill_encoder': {'n_blocks': 1, 'hidden_dim': 128, 'out_dim': 20, 'module_type': 'rnn', 'rnn_cls': 'torch.nn.LSTM', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.LayerNorm', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'batch_first': True, 'in_feature': 39}, 'skill_decoder': {'n_blocks': 5, 'hidden_dim': 128, 'out_dim': 9, 'module_type': 'linear', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.BatchNorm1d', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'in_feature': 40}, 'high_policy': {'n_blocks': 5, 'hidden_dim': 128, 'out_dim': 20, 'module_type': 'linear', 'linear_cls': 'LVD.modules.base.LinearBlock', 'norm_cls': 'torch.nn.BatchNorm1d', 'act_cls': 'torch.nn.Mish', 'tanh': True, 'bias': True, 'dropout': 0, 'in_feature': 60}},\n",
       " 'env': {'env_name': 'kitchen', 'env_name_offline': 'kitchen-mixed-v0', 'robotics': True, 'state_dim': 30, 'n_obj': 9, 'n_env': 21, 'n_goal': 30, 'action_dim': 9, 'normalize': False, 'subseq_len': 11, 'max_seq_len': 280, 'data_dir': '.', 'epoch_cycles_train': 50, 'batch_size': 1024, 'mixin_start': 30, 'mixin_ratio': 0.05, 'plan_H': 100, 'epochs': 70, 'warmup_steps': 30, 'latent_dim': 10, 'latent_state_dim': 32, 'reg_beta': 0.0005, 'prior_state_dim': 30, 'wae_coef': 1, 'val_data_size': 5000, 'time_limit': 280, 'target_kl_start': 50, 'target_kl_end': 15, 'init_alpha': 0.0005, 'only_increase': True, 'auto_alpha': False, 'reuse_rate': 512, 'q_warmup': 5000, 'q_weight': 1, 'precollect': 20, 'early_stop_threshold': 0.8, 'max_reward': 4, 'use_hidden': True, 'consistency_lr': 1e-08, 'policy_lr': 3e-06},\n",
       " 'dataset_cls': LVD.data.kitchen.kitchen_dataloader.Kitchen_Dataset,\n",
       " 'structure': 'sc'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"/home/magenta1223/skill-based/SiMPL/GCPrior/LVD/configs/spirl_kitchen.yaml\", mode = \"rb\") as f:\n",
    "    cfg  =yaml.load(f, yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m~/anaconda3/envs/skill2/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3398\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  Input \u001b[0;32mIn [6]\u001b[0;36m in \u001b[0;35m<cell line: 1>\u001b[0;36m\u001b[0m\n\u001b[0;31m    eval(cfg['model']['skill_encoder']['in_feature'])\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    $(( 3 + 1  ))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "eval(cfg['model']['skill_encoder']['in_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skill2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
