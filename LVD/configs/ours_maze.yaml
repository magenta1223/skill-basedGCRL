defaults:
  - common
  - model: ours
  - env : maze

dataset_cls : LVD.data.Maze_Dataset_Div
structure : ours



scheduler_params:
  min_lr: 1e-6

env:
  plan_H : 500

model:
  diff:
    skill : true
  grad_pass:
    flat_D : true
  
  state_encoder :
    in_feature : ${env.state_dim} 
    latent_state_dim : ${env.latent_state_dim}
    # env_state_dim : ${env.n_env}
    # ppc_state_dim : ${add:${env.n_pos}, ${env.n_nonPos}}
    env_state_dim : 2
    ppc_state_dim : ${env.n_pos}
    pos_state_dim : ${env.n_pos}
    nonPos_state_dim : ${env.n_nonPos}
    out_dim : ${env.latent_state_dim}
  
  state_decoder :
    in_feature : ${env.latent_state_dim}
    latent_state_dim : ${env.latent_state_dim}
    # env_state_dim : ${env.n_env}
    # ppc_state_dim : ${add:${env.n_pos}, ${env.n_nonPos}}
    env_state_dim : 2
    ppc_state_dim : ${env.n_pos}
    pos_state_dim : ${env.n_pos}
    nonPos_state_dim : ${env.n_nonPos}
    out_dim : ${env.state_dim}


  dynamics :
    in_feature : ${add:${env.latent_state_dim}, ${env.skill_dim}}
    out_dim : ${env.latent_state_dim} 
  
  flat_dynamics :
    in_feature : ${add:${env.latent_state_dim}, ${env.skill_dim}}
    out_dim : ${env.latent_state_dim} 

  # not used in non-manipulation env 
  diff_decoder:
    in_feature : ${divide:${env.latent_state_dim}, 2}
    out_dim : ${env.n_nonPos}
    
  inverse_dynamics :
    in_feature : ${multiply:${env.latent_state_dim}, 2} 
    out_dim : ${multiply:${env.skill_dim}, 2}

  skill_step_goal_generator :
    in_feature : ${add:${env.latent_state_dim}, ${env.n_goal}} 
    out_dim : ${env.latent_state_dim}

  prior:
    in_feature : ${env.latent_state_dim}
    # in_feature : ${divide:${env.latent_state_dim},2}
    out_dim : ${multiply:${env.skill_dim}, 2}

  skill_encoder:
    in_feature: ${add:${env.state_dim}, ${env.action_dim}}
    # in_feature: ${add:${env.n_nonPos}, ${env.action_dim}}
    out_dim : ${multiply:${env.skill_dim}, 2}

  skill_decoder:
    in_feature : ${add:${env.state_dim}, ${env.skill_dim}}
    # in_feature : ${add:${env.n_nonPos}, ${env.skill_dim}}
    out_dim : ${env.action_dim} 
    state_dim : ${env.state_dim}
    # state_dim : ${get_statedim:${env.manipulation}, ${env.state_dim}, ${env.n_pos}}
    z_dim  : ${env.skill_dim}

  high_policy:
    in_feature : ${add:${env.latent_state_dim}, ${env.n_goal}} 
    out_dim : ${multiply:${env.skill_dim}, 2}

  goal_encoder:
    in_feature: ${add:${env.n_goal}, ${env.state_dim}} 
    out_dim : 1024 

  goal_decoder:
    in_feature: 8
    out_dim : ${env.n_goal}

  q_function:
    in_feature: ${add:${env.latent_state_dim}, ${env.n_goal}, ${env.skill_dim}} 