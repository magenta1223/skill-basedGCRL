skill_trainer : LVD.runner.Diversity_Trainer
rl_trainer : LVD.rl.GC_Skill_RL_Trainer
rlAgentCls : LVD.rl.agent.sac.SAC
buffer_cls : LVD.collector.GC_Buffer


# model learning 
diff:
  flat: true
  skill: false


grad_pass:
  flat_D : false
  skill_D : true # diff=false면 무의미 
  state_consistency : false

# for ablation 
only_flatD : false

# skill space 
tanh : true

# GCQ 
gc : true

# update inverse dynamcis and skill-step dynamcis 
consistency_update : false

# policy learning 
learning_mode : sanity_check




# ------------------ State ------------------ #

state_encoder :
  n_blocks : 5
  hidden_dim : 128 
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  tanh  : true
  dropout : 0

state_decoder :
  n_blocks : 5
  hidden_dim : 128 
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0

# ------------------ Dynamcis, Rollout ------------------ #

dynamics :
  n_blocks : 5
  hidden_dim : 128 
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0

flat_dynamics :
  n_blocks : 5
  hidden_dim : 128 
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0

diff_decoder :
  n_blocks : 3
  hidden_dim : 128 
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0

# ------------------ High level Policy ------------------ #

inverse_dynamics :
  n_blocks : 3
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0

skill_step_goal_generator :
  n_blocks  :  3
  hidden_dim  : 128
  module_type : linear
  linear_cls  : LVD.modules.LinearBlock
  norm_cls  : torch.nn.LayerNorm
  act_cls  : torch.nn.Mish
  tanh  : False
  bias  : true
  dropout : 0   

# ------------------ SPiRL ------------------ #
prior : 
  n_blocks : 5
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0

skill_encoder : 
  n_blocks : 1
  hidden_dim : 128
  module_type : rnn
  rnn_cls : torch.nn.LSTM
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0
  batch_first : true
  proj_bias : false
  return_last : true

skill_decoder : 
  n_blocks : 5
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.BatchNorm1d
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0

high_policy : 
  n_blocks : 5
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.base.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0

# ------------------ For Entropy ------------------ #

goal_encoder : 
  n_blocks : 2
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0

q_function : 
  n_blocks : 5
  hidden_dim : 128
  out_dim : 1
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls :  torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0