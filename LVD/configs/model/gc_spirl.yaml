skill_trainer : LVD.runner.BaseTrainer       # pretrain 
rl_trainer : LVD.rl.GC_Skill_RL_Trainer      # few-shot
rlAgentCls : LVD.rl.agent.sac.SAC            # rlagent 
buffer_cls : LVD.collector.GC_Buffer         # buffer class 
tanh : true                                  # skill space : tanh normal

gc : true # for gcq 

consistency_update : true # update policy by gcsl. See rl.agent.sac.SAC.update() line 119 and modules.priors.sc.StateConditioned_Prior.consistency()
model_update : true       # not used 

prior : 
  n_blocks : 5
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.base.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0

skill_encoder : 
  n_blocks : 1
  hidden_dim : 128
  module_type : rnn
  rnn_cls : torch.nn.LSTM
  linear_cls : LVD.modules.base.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0
  batch_first : true
  proj_bias : true
  
skill_decoder : 
  n_blocks : 5
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.base.LinearBlock
  norm_cls : torch.nn.BatchNorm1d
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0

high_policy : 
  n_blocks : 5
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.base.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0

q_function : 
  n_blocks : 5
  hidden_dim : 128
  out_dim : 1
  module_type : linear
  linear_cls : LVD.modules.base.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0