subseq_len : 11
tanh : true
gc : true
with_gcsl: false
sg_dist : false
negativeSamples : false
noisy_subgoal : false

buffer_cls : LVD.collector.GC_Buffer

invD_coef : 1

invD_only_f : false
mode_drop : false
grad_swap : true

advantage : false

diff:
  flat: true
  skill: false

weight :
  f : 1
  D : 1
  invD : 1

skill_trainer : LVD.runner.Diversity_Trainer
rl_trainer : LVD.rl.GCRL_Skill_Trainer
rlAgentCls : LVD.rl.agent.sac.SAC
consistency_update : true
model_update : true

goal_factor : 1

grad_pass:
  invD: false
  flat_D : true
  skill_D : true # diff=false면 무의미 
  skill : true


only_unseen : true

# ------------------ State ------------------ #

state_encoder :
  n_blocks : 5
  hidden_dim : 128 
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  tanh  : true
  dropout : 0

state_decoder :
  n_blocks : 5
  hidden_dim : 128 
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0

# ------------------ Dynamcis, Rollout ------------------ #

dynamics :
  n_blocks : 5
  hidden_dim : 128 
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0

flat_dynamics :
  n_blocks : 5
  hidden_dim : 128 
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0

diff_decoder :
  n_blocks : 3
  hidden_dim : 128 
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0

# ------------------ High level Policy ------------------ #

inverse_dynamics :
  n_blocks : 5
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0

subgoal_generator :
  n_blocks  :  5
  hidden_dim  : 128
  module_type : linear
  linear_cls  : LVD.modules.LinearBlock
  norm_cls  : torch.nn.LayerNorm
  act_cls  : torch.nn.Mish
  tanh  : False
  bias  : true
  dropout : 0   

# ------------------ SPiRL ------------------ #
prior : 
  n_blocks : 5
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0

skill_encoder : 
  n_blocks : 1
  hidden_dim : 128
  module_type : rnn
  rnn_cls : torch.nn.LSTM
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0
  batch_first : true
  proj_bias : false
  return_last : true

skill_decoder : 
  n_blocks : 5
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.BatchNorm1d
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0

# ------------------ For Entropy ------------------ #

goal_encoder : 
  n_blocks : 2
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : true
  bias : true
  dropout : 0

goal_decoder : 
  n_blocks : 2
  hidden_dim : 128
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls : torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  tanh : false
  bias : true
  dropout : 0




# 

q_function : 
  n_blocks : 5
  hidden_dim : 128
  out_dim : 1
  module_type : linear
  linear_cls : LVD.modules.LinearBlock
  norm_cls :  torch.nn.LayerNorm
  act_cls : torch.nn.Mish
  bias : true
  dropout : 0